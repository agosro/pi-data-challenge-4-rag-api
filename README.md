# ğŸ“š Challenge RAG API â€“ FastAPI + Cohere + ChromaDB

Este proyecto implementa una **API de RecuperaciÃ³n Aumentada por GeneraciÃ³n (RAG)** utilizando **FastAPI**, **Cohere** y **ChromaDB**, como parte del Challenge TÃ©cnico (Semana 4).

La API permite:
- Cargar documentos
- Generar embeddings
- Realizar bÃºsquedas semÃ¡nticas
- Responder preguntas basadas exclusivamente en el contenido cargado

Todo el sistema incorpora **buenas prÃ¡cticas de IA Responsable**, como grounding obligatorio, manejo de errores controlado y bloqueo de lenguaje inapropiado.

---

## ğŸ§  Arquitectura General

**Flujo principal:**

1. **Upload** â†’ Se almacena el documento
2. **Generate Embeddings** â†’ El documento se fragmenta y se vectoriza
3. **Search** â†’ Se recuperan fragmentos relevantes usando similitud semÃ¡ntica
4. **Ask** â†’ El LLM responde solo con el contexto recuperado (RAG)

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **FastAPI** â€“ Framework para la API
- **Uvicorn** â€“ Servidor ASGI
- **Cohere API** â€“ GeneraciÃ³n de embeddings y respuestas con LLM
- **ChromaDB** â€“ Vector store local persistente
- **LangChain** â€“ Chunking de texto (RecursiveCharacterTextSplitter)
- **python-dotenv** â€“ Manejo de variables de entorno

---

## ğŸ“¦ InstalaciÃ³n

### 1ï¸âƒ£ Clonar el repositorio

```bash
git clone https://github.com/tu-usuario/challenge-rag-fastapi-cohere.git
cd challenge-rag-fastapi-cohere
````

### 2ï¸âƒ£ Crear entorno virtual

```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

### 3ï¸âƒ£ Instalar dependencias

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Configurar variables de entorno

Crear un archivo `.env` en la raÃ­z del proyecto:

```env
CO_API_KEY=tu_api_key_aqui
```

---

## â–¶ï¸ Ejecutar la API

```bash
uvicorn main:app --reload
```

La documentaciÃ³n interactiva estarÃ¡ disponible en:

* ğŸ‘‰ [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs) (Swagger)
* ğŸ‘‰ [http://127.0.0.1:8000/redoc](http://127.0.0.1:8000/redoc)

---

## ğŸ”Œ Endpoints Principales

### ğŸ“¥ POST `/upload`

Carga un nuevo documento en el sistema.

### ğŸ§© POST `/generate-embeddings`

Genera embeddings para un documento previamente cargado.

### ğŸ” POST `/search`

Realiza una bÃºsqueda semÃ¡ntica sobre los documentos almacenados.

### â“ POST `/ask`

Responde una pregunta utilizando Ãºnicamente el contexto recuperado desde `/search`.

Incluye:

* `grounded`: indica si la respuesta se basÃ³ en contexto real
* `context_used`: fragmento utilizado
* `similarity_score`: similitud del fragmento mÃ¡s relevante

---

## ğŸ›¡ï¸ Principios de IA Responsable

âœ” **Grounding obligatorio**
âœ” **No se inventa informaciÃ³n**
âœ” **Bloqueo de lenguaje inapropiado**
âœ” **No exposiciÃ³n de datos sensibles**
âœ” **Mensajes de error genÃ©ricos**
âœ” **Logs sin contenido sensible**

Si no hay informaciÃ³n suficiente, la API responde:

```
"No cuento con informaciÃ³n suficiente para responder a esta consulta."
```

---

## ğŸ“ Estructura del Proyecto

```text
.
â”œâ”€â”€ main.py
â”œâ”€â”€ routers/
â”‚   â”œâ”€â”€ upload_router.py
â”‚   â”œâ”€â”€ embedding_router.py
â”‚   â”œâ”€â”€ search_router.py
â”‚   â””â”€â”€ ask_router.py
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ store.py
â”‚   â”œâ”€â”€ embeddings.py
    â”œâ”€â”€ chunker.py
â”‚   â”œâ”€â”€ vectorstore.py
â”‚   â”œâ”€â”€ search.py
â”‚   â”œâ”€â”€ llm.py
â”‚   â”œâ”€â”€ moderation.py
â”‚   â””â”€â”€ logging.py
â”œâ”€â”€ models/
â”‚   â””â”€â”€ schemas.py            
â”œâ”€â”€ requirements.txt
â””â”€â”€ .env
```

---

## ğŸ‘¤ Autora

**Agostina RocÃ­o Torres**
Analista de Sistemas

---

## ğŸ“Œ Notas Finales

Este proyecto fue desarrollado con foco en:

* claridad arquitectÃ³nica
* separaciÃ³n de responsabilidades
* prÃ¡cticas responsables de uso de modelos de lenguaje

```

---
